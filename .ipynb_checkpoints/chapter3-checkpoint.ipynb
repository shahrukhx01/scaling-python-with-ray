{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essentials of Ray Remote Functions\n",
    "When you call a remote function, it immediately returns an ObjectRef (a future),\n",
    "which is a reference to a remote object. Ray creates and executes a task in the\n",
    "background on a separate worker process and writes the result when finished into the\n",
    "original reference. You can then call ray.get on the ObjectRef to obtain the value.\n",
    "Note that ray.get is a blocking method waiting for task execution to complete before\n",
    "returning the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Objects in Ray\n",
    "A remote object is just an object, which may be on another node. ObjectRefs are like\n",
    "pointers or IDs to objects that you can use to get the value from, or status of, the\n",
    "remote function. In addition to being created from remote function calls, you can\n",
    "also create ObjectRefs explicitly by using the ray.put function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example converts the\n",
    "iterator to a list before passing it to ray.get. You need to do this when calling\n",
    "ray.get takes in a list of futures or an individual future.1\n",
    "The function waits until it has all the objects so it can return the list in order <br/><br/>\n",
    "\n",
    "As with regular Ray remote functions, it’s important to think\n",
    "about the amount of work done inside each remote invocation.\n",
    "For example, using ray.remote to compute factorials recursively\n",
    "will be slower than doing it locally since the work inside each\n",
    "function is small even though the overall work can be large. The\n",
    "exact amount of time depends on how busy your cluster is, but as a\n",
    "general rule, anything executed in under a few seconds without any\n",
    "special resources is not worth scheduling remotely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Functions Lifecycle\n",
    "The invoking Ray process (called the owner) of a remote function schedules the\n",
    "execution of a submitted task and facilitates the resolution of the returned ObjectRef\n",
    "to its underlying value if needed. <br/><br/>\n",
    "On task submission, the owner waits for all dependencies (i.e., ObjectRef objects that\n",
    "were passed as an argument to the task) to become available before scheduling. The\n",
    "dependencies can be local or remote, and the owner considers the dependencies to be\n",
    "ready as soon as they are available anywhere in the cluster. When the dependencies\n",
    "are ready, the owner requests resources from the distributed scheduler to execute the\n",
    "task. Once resources are available, the scheduler grants the request and responds with\n",
    "the address of a worker that will execute the function.<br/><br/>\n",
    "At this point, the owner sends the task specification over gRPC to the worker. After\n",
    "executing the task, the worker stores the return values. If the return values are small\n",
    "(less than 100 KiB by default), the worker returns the values inline directly to the\n",
    "owner, which copies them to its in-process object store. If the return values are large,\n",
    "the worker stores the objects in its local shared memory store and replies to the\n",
    "owner, indicating that the objects are now in distributed memory. This allows the\n",
    "owner to refer to the objects without having to fetch the objects to its local node.\n",
    "When a task is submitted with an ObjectRef as its argument, the worker must resolve\n",
    "its value before it can start executing the task.<br/><br/>\n",
    "Tasks can end in an error. Ray distinguishes between two types of task errors:<br/><br/>\n",
    "**Application-level**<br/>\n",
    "In this scenario, the worker process is alive, but the task ends in an error (e.g., a\n",
    "task that throws an IndexError in Python).<br/><br/>\n",
    "**System-level**<br/>\n",
    "In this scenario, the worker process dies unexpectedly (e.g., a process that seg‐\n",
    "faults, or if the worker’s local Raylet dies).<br/><br/>\n",
    "Tasks that fail because of application-level errors are never retried. The exception\n",
    "is caught and stored as the return value of the task. Tasks that fail because of system-level errors may be automatically retried up to a specified number of attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "\n",
    "things = list(range(20))\n",
    "things.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def remote_task(x):\n",
    " time.sleep(x)\n",
    " return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you recall, the example remote function sleeps based on the input argument.\n",
    "Since the range is in ascending order, calling the remote function on it will result\n",
    "in futures that are completed in order. To ensure that the futures won’t complete\n",
    "in order, you will need to modify the list. One way you can do this is by calling\n",
    "things.sort(reverse=True) prior to mapping your remote function over things <br/><br/>\n",
    "To see the difference between using ray.get and ray.wait, you can write a function\n",
    "that collects the values from your futures with some time delay on each object to\n",
    "simulate business logic<br/><br/>\n",
    "The first option, not using ray.wait, is a bit simpler and cleaner to read, as shown in\n",
    "Example 3-2, but is not recommended for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 06:47:44,120\tINFO worker.py:1642 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Completed 19\n",
      " Completed 18\n",
      " Completed 17\n",
      " Completed 16\n",
      " Completed 15\n",
      " Completed 14\n",
      " Completed 13\n",
      " Completed 12\n",
      " Completed 11\n",
      " Completed 10\n",
      " Completed 9\n",
      " Completed 8\n",
      " Completed 7\n",
      " Completed 6\n",
      " Completed 5\n",
      " Completed 4\n",
      " Completed 3\n",
      " Completed 2\n",
      " Completed 1\n",
      " Completed 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" waits for all futures to complete in the order in which they were submitted. \n",
    "Wasteful when each remote future has different execution time. \n",
    "Hence, you'd be stuck atleast as long as the long running future.\n",
    "\"\"\"\n",
    "def in_order():\n",
    " # Make the futures\n",
    " futures = list(map(lambda x: remote_task.remote(x), things))\n",
    " values = ray.get(futures)\n",
    " for v in values:\n",
    "    print(f\" Completed {v}\")\n",
    "    time.sleep(1) # Business logic goes here\n",
    "   \n",
    "in_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second option is a bit more complex, as shown in Example 3-3. This works by\n",
    "calling ray.wait to find the next available future and iterating until all the futures\n",
    "have been completed. ray.wait returns two lists, one of the object references for\n",
    "completed tasks (of the size requested, which defaults to 1) and another list of the rest\n",
    "of the object references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready 1 rest 19\n",
      "completed value ObjectRef(a02c24b8b7fc0a31ffffffffffffffffffffffff0100000001000000), result 10\n",
      "Ready 1 rest 18\n",
      "completed value ObjectRef(347cc60e0bb3da74ffffffffffffffffffffffff0100000001000000), result 11\n",
      "Ready 1 rest 17\n",
      "completed value ObjectRef(88543757a8df6d2fffffffffffffffffffffffff0100000001000000), result 12\n",
      "Ready 1 rest 16\n",
      "completed value ObjectRef(bcb4fef46b376cafffffffffffffffffffffffff0100000001000000), result 13\n",
      "Ready 1 rest 15\n",
      "completed value ObjectRef(cae5e964086715a4ffffffffffffffffffffffff0100000001000000), result 14\n",
      "Ready 1 rest 14\n",
      "completed value ObjectRef(3d3e27c54ed1f5cfffffffffffffffffffffffff0100000001000000), result 15\n",
      "Ready 1 rest 13\n",
      "completed value ObjectRef(465c0fb8d6cb3cdcffffffffffffffffffffffff0100000001000000), result 16\n",
      "Ready 1 rest 12\n",
      "completed value ObjectRef(c76a79b2875a7251ffffffffffffffffffffffff0100000001000000), result 17\n",
      "Ready 1 rest 11\n",
      "completed value ObjectRef(dc746dc61b2c1923ffffffffffffffffffffffff0100000001000000), result 18\n",
      "Ready 1 rest 10\n",
      "completed value ObjectRef(a6d6d59239756144ffffffffffffffffffffffff0100000001000000), result 2\n",
      "Ready 1 rest 9\n",
      "completed value ObjectRef(c5db14a0419b947bffffffffffffffffffffffff0100000001000000), result 6\n",
      "Ready 1 rest 8\n",
      "completed value ObjectRef(18b2ad3c688fb947ffffffffffffffffffffffff0100000001000000), result 19\n",
      "Ready 1 rest 7\n",
      "completed value ObjectRef(c1464dc5b2308f10ffffffffffffffffffffffff0100000001000000), result 7\n",
      "Ready 1 rest 6\n",
      "completed value ObjectRef(79cc316456d39201ffffffffffffffffffffffff0100000001000000), result 8\n",
      "Ready 1 rest 5\n",
      "completed value ObjectRef(ae46b8beecd25f3affffffffffffffffffffffff0100000001000000), result 4\n",
      "Ready 1 rest 4\n",
      "completed value ObjectRef(aa3d5d11e415fe88ffffffffffffffffffffffff0100000001000000), result 3\n",
      "Ready 1 rest 3\n",
      "completed value ObjectRef(6efb86ef2d286c40ffffffffffffffffffffffff0100000001000000), result 0\n",
      "Ready 1 rest 2\n",
      "completed value ObjectRef(a631fe8d231813bfffffffffffffffffffffffff0100000001000000), result 9\n",
      "Ready 1 rest 1\n",
      "completed value ObjectRef(91581beb08e6c9deffffffffffffffffffffffff0100000001000000), result 5\n",
      "Ready 1 rest 0\n",
      "completed value ObjectRef(c7528efcb2fd36edffffffffffffffffffffffff0100000001000000), result 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"performs lazy evaluation of futures in arbitrary order, \n",
    "which means it would wait until the completion of next future\n",
    " and pull results instead of waiting for all to complete, and\n",
    "will iterate until all the futures have been resolved.\n",
    "\"\"\"\n",
    "def as_available():\n",
    " # Make the futures\n",
    " futures = list(map(lambda x: remote_task.remote(x), things))\n",
    " # While we still have pending futures\n",
    " while len(futures) > 0:\n",
    "    ready_futures, rest_futures = ray.wait(futures)\n",
    "    print(f\"Ready {len(ready_futures)} rest {len(rest_futures)}\")\n",
    "    for id in ready_futures:\n",
    "        print(f'completed value {id}, result {ray.get(id)}')\n",
    "        time.sleep(1) # Business logic goes here\n",
    "    # We just need to wait on the ones that are not yet available\n",
    "    futures = rest_futures\n",
    "as_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running these functions side by side with timeit.time, you can see the difference\n",
    "in performance. It’s important to note that this performance improvement depends\n",
    "on how long the nonparallelized business logic (the logic in the loop) takes. If you’re\n",
    "just summing the results, using ray.get directly could be OK, but if you’re doing\n",
    "something more complex, you should use ray.wait. When we run this, we see that\n",
    "ray.wait performs roughly twice as fast. You can try varying the sleep times and see\n",
    "how it works out.<br/><br/>\n",
    "You may wish to specify one of the few optional parameters to ray.wait:<br/><br/>\n",
    "**num_returns**<br/><br/>\n",
    "The number of ObjectRef objects for Ray to wait for completion before return‐\n",
    "ing. You should set num_returns to less than or equal to the length of the input\n",
    "list of ObjectRef objects; otherwise, the function throws an exception.2 The\n",
    "default value is 1.<br/><br/>\n",
    "**timeout**<br/><br/>\n",
    "The maximum amount of time in seconds to wait before returning. This defaults\n",
    "to −1 (which is treated as infinite).<br/><br/>\n",
    "**fetch_local**<br/><br/>\n",
    "You can disable fetching of results by setting this to false if you are interested\n",
    "only in ensuring that the futures are completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray’s get and wait functions handle timeouts slightly differently. Ray doesn’t raise an\n",
    "exception on ray.wait when a timeout occurs; instead, it simply returns fewer ready\n",
    "futures than num_returns. However, if ray.get encounters a timeout, Ray will raise a\n",
    "GetTimeoutError. Note that the return of the wait/get function does not mean that\n",
    "your remote function will be terminated; it will still run in the dedicated process. You\n",
    "can explicitly terminate your future (see the following tip) if you want to release the\n",
    "resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ray.wait can return results in any order, it’s essential to not\n",
    "depend on the order of the results. If you need to do different\n",
    "processing with different records (e.g., test a mix of group A and\n",
    "group B), you should encode this in the result (often with types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a task that does not finish in a reasonable time (e.g., a straggler), you can\n",
    "cancel the task by using ray.cancel with the same ObjectRef used to wait/get. You\n",
    "can modify the previous ray.wait example to add a timeout and cancel any “bad”\n",
    "tasks, resulting in something like Example 3-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(OSError)",
     "evalue": "\u001b[36mray::remote_task()\u001b[39m (pid=19728, ip=127.0.0.1)\n  File \"/var/folders/qj/nfsd826s231_h8sdz8nbsqqm0000gn/T/ipykernel_19711/2681013661.py\", line 3, in remote_task\nOSError: [Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(OSError)\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m    \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ready_futures:\n\u001b[0;32m---> 15\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompleted value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, result \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m    futures \u001b[38;5;241m=\u001b[39m rest_futures\n",
      "File \u001b[0;32m~/anaconda3/envs/ray/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray/lib/python3.10/site-packages/ray/_private/worker.py:2547\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 2547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mRayTaskError(OSError)\u001b[0m: \u001b[36mray::remote_task()\u001b[39m (pid=19728, ip=127.0.0.1)\n  File \"/var/folders/qj/nfsd826s231_h8sdz8nbsqqm0000gn/T/ipykernel_19711/2681013661.py\", line 3, in remote_task\nOSError: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "futures = list(map(lambda x: remote_task.remote(x), [1, threading.TIMEOUT_MAX]))\n",
    "# While we still have pending futures\n",
    "while len(futures) > 0:\n",
    " # In practice, 10 seconds is too short for most cases\n",
    " ready_futures, rest_futures = ray.wait(futures, timeout=10, num_returns=1)\n",
    " # If we get back anything less than num_returns \n",
    " if len(ready_futures) < 1:\n",
    "    print(f\"Timed out on {rest_futures}\")\n",
    "    # Canceling is a good idea for long-running, unneeded tasks\n",
    "    ray.cancel(*rest_futures)\n",
    "    # You should break since you exceeded your timeout\n",
    "    break\n",
    " for id in ready_futures:\n",
    "    print(f'completed value {id}, result {ray.get(id)}')\n",
    "    futures = rest_futures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canceling a task should not be part of your normal program flow.\n",
    "If you find yourself having to frequently cancel tasks, you should\n",
    "investigate what’s going on. Any subsequent calls to wait or get\n",
    "for a canceled task are unspecified and could raise an exception or\n",
    "return incorrect results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another minor point that we skipped in the previous chapter is that while the\n",
    "examples so far return only a single value, Ray remote functions can return multiple\n",
    "values, as with regular Python functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fault tolerance is an important consideration for those running in a distributed\n",
    "environment. Say the worker executing the task dies unexpectedly (because either the\n",
    "process crashed or the machine failed). Ray will rerun the task (after a delay) until\n",
    "either the task succeeds or the maximum number of retries is exceeded. We cover\n",
    "fault tolerance more in Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition of Remote Ray Functions\n",
    "You can make your remote functions even more powerful by composing them.\n",
    "The two most common methods of composition with remote functions in Ray are\n",
    "**pipelining** and **nested parallelism**. You can compose your functions with nested\n",
    "parallelism to express recursive functions. Ray also allows you to express sequential\n",
    "dependencies without having to block or collect the result in the driver, known as\n",
    "pipelining.\n",
    "You can build a pipelined function by using ObjectRef objects from an earlier\n",
    "ray.remote as parameters for a new remote function call. Ray will automatically\n",
    "fetch the ObjectRef objects and pass the underlying objects to your function. This\n",
    "approach allows for easy coordination between the function invocations. Addition‐\n",
    "ally, such an approach minimizes data transfer; the result will be sent directly to the\n",
    "node where execution of the second remote function is executed. A simple example\n",
    "of such a sequential calculation is presented in Example 3-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def generate_number(s: int, limit: int, sl: float) -> int :\n",
    " random.seed(s)\n",
    " time.sleep(sl)\n",
    " return random.randint(0, limit)\n",
    "\n",
    "@ray.remote\n",
    "def sum_values(v1: int, v2: int, v3: int) -> int :\n",
    " return v1+v2+v3\n",
    "\n",
    "# Get result\n",
    "print(ray.get(sum_values.remote(generate_number.remote(1, 10, .1),\n",
    " generate_number.remote(5, 20, .2), generate_number.remote(7, 15, .3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines two remote functions and then starts three instances of the first\n",
    "one. ObjectRef objects for all three instances are then used as input for the second\n",
    "function. In this case, Ray will wait for all three instances to complete before startingto execute sum_values. You can use this approach not only for passing data but\n",
    "also for expressing basic workflow style dependencies. There is no restriction on the\n",
    "number of ObjectRef objects you can pass, and you can also pass “normal” Python\n",
    "objects at the same time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You cannot use Python structures (for example, lists, dictionaries, or classes) containing ObjectRef instead of using ObjectRef directly. Ray waits for and resolves only\n",
    "ObjectRef objects that are passed directly to a function. If you attempt to pass a\n",
    "structure, you will have to do your own ray.wait and ray.get inside the function.\n",
    "Example 3-6 is a variation of Example 3-5 that does not work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(TypeError)",
     "evalue": "\u001b[36mray::sum_values()\u001b[39m (pid=19731, ip=127.0.0.1)\n  File \"/var/folders/qj/nfsd826s231_h8sdz8nbsqqm0000gn/T/ipykernel_19711/2718449464.py\", line 11, in sum_values\nTypeError: unsupported operand type(s) for +: 'int' and 'ray._raylet.ObjectRef'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(values)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# get result\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msum_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerate_number\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m       \u001b[49m\u001b[43mgenerate_number\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_number\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#end::broken_ray_remote_seq[]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray/lib/python3.10/site-packages/ray/_private/worker.py:2547\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 2547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m: \u001b[36mray::sum_values()\u001b[39m (pid=19731, ip=127.0.0.1)\n  File \"/var/folders/qj/nfsd826s231_h8sdz8nbsqqm0000gn/T/ipykernel_19711/2718449464.py\", line 11, in sum_values\nTypeError: unsupported operand type(s) for +: 'int' and 'ray._raylet.ObjectRef'"
     ]
    }
   ],
   "source": [
    "# Does not work -- Ray won't resolve any nested ObjectRefs\n",
    "#tag::broken_ray_remote_seq[]\n",
    "@ray.remote\n",
    "def generate_number(s: int, limit: int, sl: float) -> int :\n",
    "   random.seed(s)\n",
    "   time.sleep(sl)\n",
    "   return random.randint(0, limit)\n",
    "\n",
    "@ray.remote\n",
    "def sum_values(values: []) -> int :\n",
    "   return sum(values)\n",
    "\n",
    "# get result\n",
    "print(ray.get(sum_values.remote([generate_number.remote(1, 10, .1),\n",
    "       generate_number.remote(5, 20, .2), generate_number.remote(7, 15, .3)])))\n",
    "#end::broken_ray_remote_seq[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3-6 has been modified from Example 3-5 to take a list of ObjectRef\r\n",
    "objects as parameters instead of ObjectRef objects themselves. Ray does not “look\r\n",
    "inside” any structure being passed in. Therefore, the function will be invoked imme‐\r\n",
    "diately, and since types won’t match, the function will fail with an err`or TypeError:\r\n",
    "unsupported operand type(s) for +: 'int' and 'ray._raylet.ObjectR`ef'.\r\n",
    "You could fix this error by using ray.wait and ray.get, but this would still launch\r\n",
    "the function too early, resulting in unnecessary blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another composition approach, nested parallelism, your remote function launches\n",
    "additional remote functions. This can be useful in many cases, including imple‐\n",
    "menting recursive algorithms and combining hyperparameter tuning with parallel\n",
    "model training.4\n",
    " Let’s take a look at two ways to implement nested parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 3]\n",
      "completed result 1\n",
      "completed result 0\n",
      "completed result 0\n",
      "completed result 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code defines three remote functions:\n",
    "`generate_numbers`\n",
    "A simple function that generates random numbers\n",
    "`remote_objrefs`\n",
    "Invokes several remote functions and returns resulting ObjectRef objects\n",
    "`remote_values`\n",
    "Invokes several remote functions, waits for their completion, and returns the\n",
    "resulting values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#tag::nested_par[]\n",
    "@ray.remote\n",
    "def generate_number(s: int, limit: int) -> int :\n",
    "   random.seed(s)\n",
    "   time.sleep(.1)\n",
    "   return random.randint(0, limit)\n",
    "\n",
    "@ray.remote\n",
    "def remote_objrefs():\n",
    "   results = []\n",
    "   for n in range(4):\n",
    "       results.append(generate_number.remote(n, 4*n))\n",
    "   return results\n",
    "\n",
    "@ray.remote\n",
    "def remote_values():\n",
    "   results = []\n",
    "   for n in range(4):\n",
    "       results.append(generate_number.remote(n, 4*n))\n",
    "   return ray.get(results)\n",
    "\n",
    "print(ray.get(remote_values.remote()))\n",
    "futures = ray.get(remote_objrefs.remote())\n",
    "while len(futures) > 0:\n",
    "    ready_futures, rest_futures = ray.wait(futures, timeout=600, num_returns=1)\n",
    "    # If we get back anything less than num_returns there was a timeout\n",
    "    if len(ready_futures) < 1:\n",
    "        ray.cancel(*rest_futures)\n",
    "        break\n",
    "    for id in ready_futures:\n",
    "        print(f'completed result {ray.get(id)}')\n",
    "        futures = rest_futures\n",
    "#end::nested_par[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from this example, nested parallelism allows for two approaches.\n",
    "In the first case (remote_objrefs), you return all the ObjectRef objects to the\n",
    "invoker of the aggregating function. The invoking code is responsible for waiting\n",
    "for all the remote functions’ completion and processing the results. In the second\n",
    "case (remote_values), the aggregating function waits for all the remote functions’\n",
    "executions to complete and returns the actual execution results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Returning all of the ObjectRef objects allows for more flexibility with nonsequential\n",
    "consumption, as described back in ray.await, but it is not suitable for many recur‐\n",
    "sive algorithms. With many recursive algorithms (e.g., quicksort, factorial, etc.) we\n",
    "have many levels of a combination step that need to be performed, requiring that the\n",
    "results be combined at each level of recursion.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Remote Best Practices\n",
    "When you are using remote functions, keep in mind that you don’t want to make\r\n",
    "them too small. If the tasks are very small, using Ray can take longer than if you used\r\n",
    "Python without Ray. The reason for this is that every task invocation has a nontriv‐\r\n",
    "ial overhead—for example, scheduling, data passing, inter-process communication\r\n",
    "(IPC), and updating the system state. To get a real advantage from parallel execution,\r\n",
    "you need to make sure that this overhead is negligible compared to the execution\r\n",
    "time of the function itself.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in this chapter, one of the most powerful features of Ray remote is\n",
    "the ability to parallelize functions’ execution. Once you call the remote functions,\n",
    "the handle to the remote object (future) is returned immediately, and the invoker\n",
    "can continue execution either locally or with additional remote functions. If, at this\n",
    "point, you call ray.get, your code will block, waiting for a remote function to\n",
    "complete, and as a result, you will have no parallelism. **To ensure parallelization of\n",
    "your code, you should invoke ray.get only at the point when you absolutely need\n",
    "the data to continue the main thread of execution. Moreover, as we’ve described, it is\n",
    "recommended to use ray.wait instead of ray.get directly. Additionally, if the result\n",
    "of one remote function is required for the execution of another remote function(s),\n",
    "consider using pipelining (described previously) to leverage Ray’s task coordination.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you submit your parameters to remote functions, Ray does not submit them\n",
    "directly to the remote function, but rather copies the parameters into object storage\n",
    "and then passes ObjectRef as a parameter. As a result, if you send the same parame‐\n",
    "ter to multiple remote functions, you are paying a (performance) penalty for storing\n",
    "the same data to the object storage several times. The larger the size of the data, the\n",
    "larger the penalty. To avoid this, if you need to pass the same data to multiple remote\n",
    "functions, a better option is to first put the shared data in object storage and use the\n",
    "resulting ObjectRef as a parameter to the function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " remote function invocation is done by the Raylet\n",
    "component. If you invoke a lot of remote functions from a single client, all these\n",
    "invocations are done by a single Raylet. Therefore, it takes a certain amount of time\n",
    "for a given Raylet to process these requests, which can cause a delay in starting all\n",
    "the functions. A better approach, as described in the “Ray Design Patterns” documen‐\n",
    "tation, is to use an invocation tree—a nested function invocation as described in the\n",
    "previous section. Basically, a client creates several remote functions, each of which, in\n",
    "turn, creates more remote functions, and so on. In this approach, the invocations are\n",
    "spread across multiple Raylets, allowing scheduling to happen faster. <br/><br/>\n",
    "Every time you define a remote function by using the @ray.remote decorator, Ray\n",
    "exports these definitions to all Ray workers, which takes time (especially if you have a\n",
    "lot of nodes). To reduce the number of function exports, a good practice is to define\n",
    "as many of the remote tasks on the top level outside the loops and local functions\n",
    "using them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing It Together with an Example\n",
    "ML models composed of other models (e.g., ensemble models) are well suited to\r\n",
    "evaluation with Ray. Example 3-8 shows what it looks like to use Ray’s function\r\n",
    "composition for a hypothetical spam model for web links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n",
      "[False]\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def fetch(url: str) -> Tuple[str, str]:\n",
    "    import urllib.request\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "       return (url, response.read())\n",
    "\n",
    "@ray.remote\n",
    "def has_spam(site_text: Tuple[str, str]) -> bool:\n",
    "    # Open the list of spammers or download it\n",
    "    spammers_url = (\n",
    "        \"https://raw.githubusercontent.com/matomo-org/referrer-spam-list/master/spammers.txt\"\n",
    "    )\n",
    "    import urllib.request\n",
    "    with urllib.request.urlopen(spammers_url) as response:\n",
    "            spammers = response.readlines()\n",
    "            for spammer in spammers:\n",
    "                if spammer in site_text[1]:\n",
    "                    return True\n",
    "    return False\n",
    "            \n",
    "    \n",
    "@ray.remote\n",
    "def fake_spam1(us: Tuple[str, str]) -> bool:\n",
    "    # You should do something fancy here with TF or even just NLTK\n",
    "    time.sleep(10)\n",
    "    if random.randrange(10) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "@ray.remote\n",
    "def fake_spam2(us: Tuple[str, str]) -> bool:\n",
    "    # You should do something fancy here with TF or even just NLTK\n",
    "    time.sleep(5)\n",
    "    if random.randrange(10) > 4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "@ray.remote\n",
    "def combine_is_spam(us: Tuple[str, str], model1: bool, model2: bool, model3: bool) -> Tuple[str, str, bool]:\n",
    "    # Questionable fake ensemble\n",
    "    score = model1 * 0.2 + model2 * 0.4 + model3 * 0.4\n",
    "    if score > 0.2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#end::bring_it_together_with_ensemble[]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "urls = [\"https://www.espncricinfo.com/\", \"http://www.google.com\", \"http://www.holdenkarau.com\"]\n",
    "site_futures = map(lambda url: fetch.remote(url), urls)\n",
    "spam_futures = map(lambda us: [us, has_spam.remote(us), fake_spam1.remote(us), fake_spam2.remote(us)],\n",
    "                   site_futures)\n",
    "info_futures = map(lambda i: combine_is_spam.remote(*i), spam_futures)\n",
    "                   \n",
    "                   \n",
    "not_ready = list(info_futures)\n",
    "while len(not_ready) > 0:\n",
    "    ready, not_ready = ray.wait(not_ready, num_returns = 1)\n",
    "    if len(ready) < 1:\n",
    "        raise Exception(\"Error fetching futures\")\n",
    "    print(ray.get(ready))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Ray instead of taking the summation of the time to evaluate all the models,\r\n",
    "you instead need to wait for only the slowest model, and all other models that\r\n",
    "finish faster are “free.” For example, if the models take equal lengths of time to run,\r\n",
    "evaluating these models serially, without Ray, would take almost three times as long.\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
